{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sha1', 'md5', 'sha3_256', 'sha384', 'shake_128', 'sha256', 'blake2b', 'sha3_384', 'sha3_512', 'shake_256', 'sha224', 'sha512', 'sha3_224', 'blake2s'}\n"
     ]
    }
   ],
   "source": [
    "import hashlib \n",
    "# print(hashlib.algorithms_available)\n",
    "print(hashlib.algorithms_guaranteed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b',\\xe1\\xff7\\xe7\\xa0\\xe7\\xb2\\xb4\\xf9E!\\xf2\\xd9\\xb8;\\xdf\\x7f\\x10\\xa8\\x1ad1\\xc0\\x7f=\\xbb\\xb1\\xf7\\xeb7\\xcf'\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "# Initialize the empty message using SHA-256\n",
    "message = hashlib.sha256()\n",
    " \n",
    "# Update the message using byte strings\n",
    "message.update(b'Hello there,')\n",
    "message.update(b'how are you?')\n",
    " \n",
    "# Print the message digest\n",
    "print(message.digest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\BTP Version_1\n"
     ]
    }
   ],
   "source": [
    "!echo %cd%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Desktop\\BTP Version_1\n"
     ]
    }
   ],
   "source": [
    "!cd datasets\n",
    "!echo %cd%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'zip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!zip -F datasets/pix2code_datasets.zip --out datasets/datasets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([3,1,44444342,566565653, 3455455332,5,6,7,8,9,0,4,3,6,7,8,6,3,5,5])\n",
    "x = np.array2string(x, precision=2, separator=',',\n",
    "                      max_line_width=4545)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.get_printoptions()['linewidth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[         3,         1,  44444342, 566565653,3455455332,         5,         6,         7,         8,         9,         0,         4,         3,         6,         7,         8,         6,         3,         5,         5]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 16, 16)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dense, RepeatVector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1024)\n",
      "(None, 48, 1024)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "layer_1 = Dense(1024, input_shape=(8,)) \n",
    "model.add(layer_1) \n",
    "layer_2 = RepeatVector(48) \n",
    "model.add(layer_2) \n",
    "\n",
    "print(layer_2.input_shape) \n",
    "print(layer_2.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1024)              9216      \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVect  (None, 48, 1024)         0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,216\n",
      "Trainable params: 9,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ws9/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def compute_batch_total_bleu():\n",
    "    '''Compute the total BLEU score over elements in a batch\n",
    "    '''\n",
    "    pathcode = 'Code'\n",
    "    pathorg = 'datasets/web/EVALUATION_SET'\n",
    "    ref_list = []\n",
    "    cand_list = []\n",
    "    for i in os.listdir(pathorg):\n",
    "        s = []\n",
    "        if i.endswith('.gui'):\n",
    "            with open(os.path.join(pathorg, i)) as f:\n",
    "                \n",
    "                for line in f.readlines():\n",
    "                    for token in word_tokenize(line):\n",
    "                        s.append(token)\n",
    "        \n",
    "\n",
    "            ref_list.append(s)\n",
    "    \n",
    "    for i in os.listdir(pathcode):\n",
    "        s = []\n",
    "        if i.endswith('.gui'):\n",
    "            with open(os.path.join(pathcode, i)) as f:\n",
    "                \n",
    "                for line in f.readlines():\n",
    "                    for token in word_tokenize(line):\n",
    "                        s.append(token)\n",
    "        \n",
    "\n",
    "            cand_list.append(s)\n",
    "    return (ref_list,cand_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_list,cand_list = compute_batch_total_bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ws9/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/ws9/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/ws9/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.613408270960613e-232\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "sum = 0\n",
    "for candidate in enumerate(cand_list):\n",
    "    score = sentence_bleu(ref_list, candidate)\n",
    "    sum += score\n",
    "print(sum/250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ws9/.local/lib/python3.8/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "score = sentence_bleu(ref_list, [\"header\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.117940420322104e-237\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
